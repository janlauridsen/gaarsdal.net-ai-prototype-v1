AI-model-adapter (model-agnostisk)

FormÃ¥l med TRIN 6:
At indfÃ¸re Ã©t, rent interface til en AI-model, sÃ¥dan at:

resten af systemet er ligeglad med hvilken model der bruges

modellen kan skiftes senere uden arkitekturÃ¦ndring

al model-specifik kode er isoleret Ã©t sted

ğŸ‘‰ Ingen routing
ğŸ‘‰ Ingen modes
ğŸ‘‰ Ingen tool-calling
ğŸ‘‰ Kun â€œprompt ind â†’ tekst udâ€

1ï¸âƒ£ Designprincip

Adapteren skal:

tage Ã©n fÃ¦rdig prompt (string)

returnere Ã©n tekst (string)

skjule alle detaljer om API, SDK, headers osv.

Alt andet er stÃ¸j.

2ï¸âƒ£ Bevidst valg (i denne iteration)

Vi bruger Ã©n model

Ingen streaming

Ingen temperature-styring

Ingen retries

Ingen fallback-modeller

ğŸ‘‰ Det er lÃ¦rings- og arkitekturprototype, ikke robust drift.

3ï¸âƒ£ MiljÃ¸variabel

I .env.example (udvidelse):

OPENAI_API_KEY=


(Selvom arkitekturen er model-agnostisk, skal vi vÃ¦lge Ã©n konkret model for at kunne kÃ¸re noget.)

4ï¸âƒ£ Kode: /lib/ai/adapter.ts

Dette er hele adapteren.

import OpenAI from "openai";

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

export async function generateResponse(
  prompt: string
): Promise<string> {
  const response = await client.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [
      {
        role: "system",
        content: prompt,
      },
    ],
  });

  return response.choices[0]?.message?.content ?? "";
}


ğŸ‘‰ BemÃ¦rk:

Resten af systemet ved intet om OpenAI

Udskiftning = Ã¦ndr denne fil, intet andet

5ï¸âƒ£ Kendte begrÃ¦nsninger (accepterede)

Prompt sendes som Ã©n system-besked

Ingen rolle-separation (system/user)

Ingen token-kontrol

Ingen fejl-hÃ¥ndtering

Alt dette kan komme senere, uden arkitekturÃ¦ndring.

6ï¸âƒ£ Output af TRIN 6

Efter dette trin har du:

En fungerende AI-abstraktion

Ã‰t stabilt kald: generateResponse(prompt)

Et system klar til at blive koblet sammen
